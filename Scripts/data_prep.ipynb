{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_file = '../Data/analyzed_stock_data.csv'\n",
    "reddit_data = pd.read_csv(reddit_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_data['date_only'] = pd.to_datetime(reddit_data['date_only'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stock_data(tickers, start_date, end_date):\n",
    "    stock_data = []\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            print(f\"Fetching data for {ticker}...\")\n",
    "            data = yf.download(ticker, start=start_date, end=end_date)\n",
    "            if not data.empty:\n",
    "                data['ticker'] = ticker\n",
    "                \n",
    "                data['date_only_'] = data.index.date\n",
    "                \n",
    "                data.columns = [f\"{col[0]}_{col[1]}\" if isinstance(col, tuple) else col for col in data.columns]\n",
    "                \n",
    "                data.rename(columns={col: 'date_only' if 'date_only' in col else col for col in data.columns}, inplace=True)\n",
    "                print(f\"Date_only column added for {ticker}. Columns: {data.columns}\")\n",
    "                stock_data.append(data)\n",
    "            else:\n",
    "                print(f\"No data found for {ticker}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {ticker}: {e}\")\n",
    "    \n",
    "    \n",
    "    if stock_data:\n",
    "        combined_data = pd.concat(stock_data, ignore_index=True)\n",
    "        print(f\"Combined stock data columns: {combined_data.columns}\")\n",
    "    else:\n",
    "        combined_data = pd.DataFrame()  \n",
    "        print(\"No stock data fetched.\")\n",
    "\n",
    "    \n",
    "    if 'date_only' in combined_data.columns:\n",
    "        combined_data['date_only'] = pd.to_datetime(combined_data['date_only'])\n",
    "    else:\n",
    "        print(\"Warning: 'date_only' column not found in combined stock data.\")\n",
    "\n",
    "    return combined_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date_only column added for AI. Columns: Index(['Adj Close_AI', 'Close_AI', 'High_AI', 'Low_AI', 'Open_AI', 'Volume_AI',\n",
      "       'ticker_', 'date_only'],\n",
      "      dtype='object')\n",
      "Fetching data for MSTR...\n",
      "Date_only column added for MSTR. Columns: Index(['Adj Close_MSTR', 'Close_MSTR', 'High_MSTR', 'Low_MSTR', 'Open_MSTR',\n",
      "       'Volume_MSTR', 'ticker_', 'date_only'],\n",
      "      dtype='object')\n",
      "Fetching data for NVDA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date_only column added for NVDA. Columns: Index(['Adj Close_NVDA', 'Close_NVDA', 'High_NVDA', 'Low_NVDA', 'Open_NVDA',\n",
      "       'Volume_NVDA', 'ticker_', 'date_only'],\n",
      "      dtype='object')\n",
      "Fetching data for VOO...\n",
      "Date_only column added for VOO. Columns: Index(['Adj Close_VOO', 'Close_VOO', 'High_VOO', 'Low_VOO', 'Open_VOO',\n",
      "       'Volume_VOO', 'ticker_', 'date_only'],\n",
      "      dtype='object')\n",
      "Combined stock data columns: Index(['Adj Close_AI', 'Close_AI', 'High_AI', 'Low_AI', 'Open_AI', 'Volume_AI',\n",
      "       'ticker_', 'date_only', 'Adj Close_MSTR', 'Close_MSTR', 'High_MSTR',\n",
      "       'Low_MSTR', 'Open_MSTR', 'Volume_MSTR', 'Adj Close_NVDA', 'Close_NVDA',\n",
      "       'High_NVDA', 'Low_NVDA', 'Open_NVDA', 'Volume_NVDA', 'Adj Close_VOO',\n",
      "       'Close_VOO', 'High_VOO', 'Low_VOO', 'Open_VOO', 'Volume_VOO'],\n",
      "      dtype='object')\n",
      "date_only column found in stock data!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tickers = ['AI', 'MSTR', 'NVDA', 'VOO']\n",
    "start_date = (datetime.now() - pd.DateOffset(months=6)).strftime('%Y-%m-%d')\n",
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "combined_stock_data = fetch_stock_data(tickers, start_date, end_date)\n",
    "\n",
    "if 'date_only' in combined_stock_data.columns:\n",
    "    print(\"date_only column found in stock data!\")\n",
    "else:\n",
    "    print(\"date_only column not found in stock data.\")\n",
    "\n",
    "\n",
    "combined_stock_data = combined_stock_data.reset_index(drop=True)\n",
    "reddit_data = reddit_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge Successful\n"
     ]
    }
   ],
   "source": [
    "merged_data = pd.merge(\n",
    "    reddit_data, combined_stock_data, on='date_only', how='inner'\n",
    ")\n",
    "print('Merge Successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.drop(columns=['date_only', 'created_utc'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Sentiment Data saved to ../Data/stock_sentiment_combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "output_file = '../Data/stock_sentiment_combined_data.csv'\n",
    "merged_data.to_csv(output_file, index=False)\n",
    "print(f'Stock Sentiment Data saved to {output_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
